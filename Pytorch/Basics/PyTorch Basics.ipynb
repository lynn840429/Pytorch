{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch Basics.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Yoh4wZ11_esQ","colab_type":"code","colab":{}},"source":["import torch \n","import torchvision\n","import torch.nn as nn\n","import numpy as np\n","import torchvision.transforms as transforms"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqaTSXB6_vY5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"999e097d-6140-4047-b519-279da8b9c78c","executionInfo":{"status":"ok","timestamp":1574776643603,"user_tz":-480,"elapsed":1474,"user":{"displayName":"Lynn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAA3iweeMBLyNHjfWr2cL84enkEcjNXptNrvoZJUw=s64","userId":"13191593999274530441"}}},"source":["# ================================================================== #\n","#                     1. Basic autograd example 1                    #\n","# ================================================================== #\n","\n","# Create tensors.\n","x = torch.tensor(1., requires_grad=True)\n","w = torch.tensor(2., requires_grad=True)\n","b = torch.tensor(3., requires_grad=True)\n","print(x, w, b)\n","\n","# Build a computational graph.\n","y = w * x + b    # y = 2 * x + 3\n","print(y)\n","\n","# Compute gradients.\n","y.backward()\n","\n","# Print out the gradients.\n","print(x.grad)    # x.grad = 2 \n","print(w.grad)    # w.grad = 1 \n","print(b.grad)    # b.grad = 1\n","print(x, w, b)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor(1., requires_grad=True) tensor(2., requires_grad=True) tensor(3., requires_grad=True)\n","tensor(5., grad_fn=<AddBackward0>)\n","tensor(2.)\n","tensor(1.)\n","tensor(1.)\n","tensor(1., requires_grad=True) tensor(2., requires_grad=True) tensor(3., requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jKNBT96NBoA2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"88bed4c7-8bfe-4f82-e2fa-5f7547cc65dd","executionInfo":{"status":"ok","timestamp":1574778782805,"user_tz":-480,"elapsed":1317,"user":{"displayName":"Lynn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAA3iweeMBLyNHjfWr2cL84enkEcjNXptNrvoZJUw=s64","userId":"13191593999274530441"}}},"source":["# ================================================================== #\n","#                    2. Basic autograd example 2                     #\n","# ================================================================== #\n","\n","# Create tensors of shape (10, 3) and (10, 2).\n","x = torch.randn(10, 3)\n","y = torch.randn(10, 2)\n","print(\"\\nx=\", x.shape, \"\\n\", x)\n","print(\"\\ny=\", y.shape, \"\\n\", y)\n","\n","# Build a fully connected layer.\n","linear = nn.Linear(3, 2)\n","print ('\\nw: ', w.size(), \"\\n\", linear.weight)\n","print ('\\nb: ', b.size(), \"\\n\", linear.bias)\n","\n","# Build loss function and optimizer.\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n","\n","# Forward pass.\n","pred = linear(x)\n","print(\"\\nPred=\", pred.size(), \"\\n\", pred)\n","\n","pred = linear(x) - linear.bias\n","print(\"\\ny-b=\\n\", pred)\n","print(\"\\nx*w=\\n\", x.mm(linear.weight.t()))\n","\n","# Compute loss.\n","loss = criterion(pred, y)\n","print('\\nloss: ', loss.item())\n","\n","# Backward pass.\n","loss.backward()\n","\n","# Print out the gradients.\n","print ('\\ndL/dw: ', linear.weight.grad) \n","print ('\\ndL/db: ', linear.bias.grad)\n","\n","# 1-step gradient descent.\n","optimizer.step()\n","\n","# You can also perform gradient descent at the low level.\n","# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n","# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n","\n","# Print out the loss after 1-step gradient descent.\n","pred = linear(x)\n","loss = criterion(pred, y)\n","print('\\nloss after 1 step optimization: ', loss.item())"],"execution_count":36,"outputs":[{"output_type":"stream","text":["\n","x= torch.Size([10, 3]) \n"," tensor([[-1.4880, -0.3077, -0.8820],\n","        [ 0.0460, -0.1332,  0.5862],\n","        [-0.5559, -0.2460,  0.2371],\n","        [-0.5387, -0.4273,  0.1445],\n","        [-0.2552,  1.0756,  0.0940],\n","        [ 2.1430,  0.5615,  1.5352],\n","        [ 0.3507,  1.4397,  0.0123],\n","        [ 0.9934, -0.5560,  0.5396],\n","        [-1.2338,  0.3468,  0.0433],\n","        [-1.5276, -0.5685,  2.0800]])\n","\n","y= torch.Size([10, 2]) \n"," tensor([[ 6.2137e-01, -3.2991e-02],\n","        [-3.0769e-01,  7.7710e-01],\n","        [ 1.6067e-01, -2.7794e-01],\n","        [ 1.7748e+00,  4.8085e-01],\n","        [-4.4364e-01,  1.3769e+00],\n","        [-8.0836e-01, -2.5529e-04],\n","        [-1.1920e+00, -1.3232e-01],\n","        [-1.7537e+00, -9.6403e-01],\n","        [ 1.3902e+00, -2.5871e+00],\n","        [-1.0053e+00,  1.2737e+00]])\n","\n","w:  torch.Size([]) \n"," Parameter containing:\n","tensor([[-0.3682, -0.4846, -0.3882],\n","        [-0.3856,  0.4483,  0.4432]], requires_grad=True)\n","\n","b:  torch.Size([]) \n"," Parameter containing:\n","tensor([0.5706, 0.1148], requires_grad=True)\n","\n","Pred= torch.Size([10, 2]) \n"," tensor([[ 1.6099,  0.1597],\n","        [ 0.3906,  0.2972],\n","        [ 0.8024,  0.3240],\n","        [ 0.9199,  0.1950],\n","        [ 0.1068,  0.7371],\n","        [-1.0864,  0.2207],\n","        [-0.2610,  0.6305],\n","        [ 0.2648, -0.2783],\n","        [ 0.8400,  0.7652],\n","        [ 0.6011,  1.3709]], grad_fn=<AddmmBackward>)\n","\n","y-b=\n"," tensor([[ 1.0393,  0.0449],\n","        [-0.1800,  0.1824],\n","        [ 0.2318,  0.2092],\n","        [ 0.3493,  0.0802],\n","        [-0.4639,  0.6223],\n","        [-1.6570,  0.1059],\n","        [-0.8316,  0.5157],\n","        [-0.3058, -0.3931],\n","        [ 0.2694,  0.6504],\n","        [ 0.0305,  1.2560]], grad_fn=<SubBackward0>)\n","\n","x*w=\n"," tensor([[ 1.0393,  0.0449],\n","        [-0.1800,  0.1824],\n","        [ 0.2318,  0.2092],\n","        [ 0.3493,  0.0802],\n","        [-0.4639,  0.6223],\n","        [-1.6570,  0.1059],\n","        [-0.8316,  0.5157],\n","        [-0.3058, -0.3931],\n","        [ 0.2694,  0.6504],\n","        [ 0.0305,  1.2560]], grad_fn=<MmBackward>)\n","\n","loss:  1.0035151243209839\n","\n","dL/dw:  tensor([[-0.0336, -0.1316,  0.1104],\n","        [-0.2951,  0.1103,  0.0152]])\n","\n","dL/db:  tensor([0., 0.])\n","\n","loss after 1 step optimization:  1.2124805450439453\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zrMNI4xdIZ_F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"68cb42aa-ee6b-4bbd-968b-0258bc5f6b0e","executionInfo":{"status":"ok","timestamp":1574778851832,"user_tz":-480,"elapsed":994,"user":{"displayName":"Lynn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAA3iweeMBLyNHjfWr2cL84enkEcjNXptNrvoZJUw=s64","userId":"13191593999274530441"}}},"source":["# ================================================================== #\n","#                     3. Loading data from numpy                     #\n","# ================================================================== #\n","\n","# Create a numpy array.\n","x = np.array([[1, 2], [3, 4]])\n","print(x)\n","\n","# Convert the numpy array to a torch tensor.\n","y = torch.from_numpy(x)\n","print(y)\n","\n","# Convert the torch tensor to a numpy array.\n","z = y.numpy()\n","print(z)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["[[1 2]\n"," [3 4]]\n","tensor([[1, 2],\n","        [3, 4]])\n","[[1 2]\n"," [3 4]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DxKba5kfImsN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"780fea81-58ad-40ff-aad8-a33e3d3e5a6a","executionInfo":{"status":"ok","timestamp":1574779150256,"user_tz":-480,"elapsed":10098,"user":{"displayName":"Lynn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAA3iweeMBLyNHjfWr2cL84enkEcjNXptNrvoZJUw=s64","userId":"13191593999274530441"}}},"source":["# ================================================================== #\n","#                         4. Input pipline                           #\n","# ================================================================== #\n","\n","# Download and construct CIFAR-10 dataset.\n","train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n","                                             train=True, \n","                                             transform=transforms.ToTensor(),\n","                                             download=True)\n","\n","# Fetch one data pair (read data from disk).\n","image, label = train_dataset[0]\n","print (image.size())\n","print (label)\n","\n","# Data loader (this provides queues and threads in a very simple way).\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=64, \n","                                           shuffle=True)\n","\n","# When iteration starts, queue and thread start to load data from files.\n","data_iter = iter(train_loader)\n","\n","# Mini-batch images and labels.\n","images, labels = data_iter.next()\n","\n","# Actual usage of the data loader is as below.\n","i = 0\n","for images, labels in train_loader:\n","    # Training code should be written here.\n","    #pass\n","    i += 1\n","\n","print(i)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","torch.Size([3, 32, 32])\n","6\n","782\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xENX0GeyJu8j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"8058809b-2bcf-4312-8041-586b061d2c4a","executionInfo":{"status":"ok","timestamp":1574779199183,"user_tz":-480,"elapsed":7498,"user":{"displayName":"Lynn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAA3iweeMBLyNHjfWr2cL84enkEcjNXptNrvoZJUw=s64","userId":"13191593999274530441"}}},"source":["# ================================================================== #\n","#                        6. Pretrained model                         #\n","# ================================================================== #\n","\n","# Download and load the pretrained ResNet-18.\n","resnet = torchvision.models.resnet18(pretrained=True)\n","\n","# If you want to finetune only the top layer of the model, set as below.\n","for param in resnet.parameters():\n","    param.requires_grad = False\n","\n","# Replace the top layer for finetuning.\n","resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n","\n","# Forward pass.\n","images = torch.randn(64, 3, 224, 224)\n","outputs = resnet(images)\n","print (outputs.size())     # (64, 100)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n","\n","  0%|          | 0.00/44.7M [00:00<?, ?B/s]\u001b[A\n"," 11%|█         | 4.82M/44.7M [00:00<00:00, 50.5MB/s]\u001b[A\n"," 46%|████▌     | 20.6M/44.7M [00:00<00:00, 63.8MB/s]\u001b[A\n"," 80%|████████  | 35.9M/44.7M [00:00<00:00, 77.9MB/s]\u001b[A\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 130MB/s] \u001b[A"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([64, 100])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"45J7TQmwJ_ad","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":367},"outputId":"e963a0e2-487a-429a-b872-51bac6106654","executionInfo":{"status":"ok","timestamp":1574779226390,"user_tz":-480,"elapsed":960,"user":{"displayName":"Lynn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAA3iweeMBLyNHjfWr2cL84enkEcjNXptNrvoZJUw=s64","userId":"13191593999274530441"}}},"source":["# ================================================================== #\n","#                      7. Save and load the model                    #\n","# ================================================================== #\n","\n","# Save and load the entire model.\n","torch.save(resnet, 'model.ckpt')\n","model = torch.load('model.ckpt')\n","\n","# Save and load only the model parameters (recommended).\n","torch.save(resnet.state_dict(), 'params.ckpt')\n","resnet.load_state_dict(torch.load('params.ckpt'))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ResNet. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BasicBlock. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AdaptiveAvgPool2d. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":49}]}]}